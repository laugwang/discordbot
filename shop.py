import pandas as pd
import os
import re
import time
from urllib.parse import quote
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
import config


def parse_price(text):
    if not text:
        return None
    text = text.strip().replace(",", "")
    try:
        if 'è¬' in text:
            match = re.match(r'([\d.]+)', text)
            if match:
                return int(float(match.group(1)) * 10000)
        else:
            match = re.search(r'\d+', text)
            if match:
                return int(match.group(0))
    except:
        return None
    return None

def run_crawler():
    df = pd.DataFrame(columns=['é—œéµå­—', 'å“å', 'å–®åƒ¹', 'åº«å­˜', 'ç€è¦½æ•¸', 'é€£çµ'])
    os.makedirs("error_pages", exist_ok=True)

    chrome_options = Options()
    chrome_options.add_argument("--headless")  # ç„¡è¦–çª—æ¨¡å¼

    service = Service('chromedriver.exe')
    driver = webdriver.Chrome(service=service, options=chrome_options)

    for name in config.kw:  # æ¯æ¬¡åŸ·è¡Œæ™‚ç›´æ¥è®€æœ€æ–°çš„ kw
        encoded_name = quote(name.encode('utf-8'))
        url = f"https://www.8591.com.tw/mallList-list.html?searchGame=859&searchServer=944&searchKey={encoded_name}&priceSort=1"
        print("ğŸ” çˆ¬å–ä¸­:", name, "=>", url)
        time.sleep(2)
        try:
            driver.get(url)
            time.sleep(2)

            while True:
                last_height = driver.execute_script("return document.body.scrollHeight")
                while True:
                    driver.execute_script("window.scrollBy(0, 1500);")
                    time.sleep(2)
                    new_height = driver.execute_script("return document.body.scrollHeight")
                    if new_height == last_height:
                        break
                    last_height = new_height

                items = driver.find_elements(By.CLASS_NAME, "list-item")
                if not items:
                    df = pd.concat([df, pd.DataFrame({
                        'é—œéµå­—': [name],
                        'å“å': ['ç„¡'],
                        'å–®åƒ¹': ['ç„¡'],
                        'åº«å­˜': ['ç„¡'],
                        'ç€è¦½æ•¸': ['ç„¡'],
                        'é€£çµ': [driver.current_url]
                    })], ignore_index=True)
                    break

                for item in items:
                    try:
                        title = item.find_element(By.CLASS_NAME, "show-title").text
                        link_tag = item.find_element(By.CLASS_NAME, "list-item-title-txt")
                        href = link_tag.get_attribute('href') if link_tag else ''
                        link = href if href.startswith('http') else f"https://www.8591.com.tw{href}"

                        price_text = item.find_element(By.CLASS_NAME, "list-item-price").text
                        price_parsed = parse_price(price_text)
                        price = price_parsed if price_parsed is not None else 'ç„¡'

                        count_tag = item.find_element(By.CLASS_NAME, "list-item-count")
                        count_inner = count_tag.find_element(By.TAG_NAME, "div") if count_tag else None
                        count = count_inner.text.strip() if count_inner else 'ç„¡'

                        view_tag = item.find_element(By.CLASS_NAME, "list-item-view")
                        view_text = view_tag.text.strip() if view_tag else 'ç„¡'
                        view_parsed = parse_price(view_text)
                        view = view_parsed if view_parsed is not None else 'ç„¡'

                        df = pd.concat([df, pd.DataFrame({
                            'é—œéµå­—': [name],
                            'å“å': [title],
                            'å–®åƒ¹': [int(price) if price not in ['ç„¡', None] else 'ç„¡'],
                            'åº«å­˜': [int(count) if count not in ['ç„¡', None] else 'ç„¡'],
                            'ç€è¦½æ•¸': [int(view) if view not in ['ç„¡', None] else 'ç„¡'],
                            'é€£çµ': [link]
                        })], ignore_index=True)
                    except Exception as e:
                        print(f"âŒ éŒ¯èª¤ï¼š{name} => {e}")
                        continue

                try:
                    next_btn = driver.find_element(By.CSS_SELECTOR, "a.next01")
                    if next_btn and next_btn.is_displayed() and next_btn.is_enabled():
                        href_attr = next_btn.get_attribute('href')
                        if href_attr and 'javascript:;' in href_attr:
                            next_btn.click()
                            time.sleep(2)
                            continue
                except Exception:
                    pass
                break

        except Exception as e:
            print(f"âŒ éŒ¯èª¤ï¼š{name} => {e}")
            with open(f"error_pages/error_{name}.html", "w", encoding="utf-8") as f:
                f.write(driver.page_source)
            df = pd.concat([df, pd.DataFrame({
                'é—œéµå­—': [name],
                'å“å': ['éŒ¯èª¤'],
                'å–®åƒ¹': ['éŒ¯èª¤'],
                'åº«å­˜': ['éŒ¯èª¤'],
                'ç€è¦½æ•¸': ['éŒ¯èª¤'],
                'é€£çµ': [url]
            })], ignore_index=True)

    driver.quit()
    df.to_csv("result.csv", encoding="utf-8-sig", index=False)
    print("âœ… å®Œæˆï¼Œçµæœå·²å„²å­˜ç‚º result.csv")
